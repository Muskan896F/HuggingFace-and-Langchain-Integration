{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "d:\\Generative AI\\HuggingFace-and-Langchain-Integration\\generative14\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    max_length=150,\n",
    "    temperature=0.7,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    timeout=60  # Increase the timeout to 60 seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "Machine Learning (ML) is a subset of Artificial Intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.\n",
      "\n",
      "The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide.\n",
      "\n",
      "Machine learning is already widely in use today:\n",
      "\n",
      "- Email filtering\n",
      "- Recommendation systems\n",
      "- Ad targeting\n",
      "- Sentiment analysis\n",
      "- Fraud detection\n",
      "- Autonomous vehicles\n",
      "- Speech recognition\n",
      "- and much more!\n",
      "\n",
      "The Rise of Machine Learning\n",
      "\n",
      "As the volume of data generated by the world increases, the demand for machine learning is growing exponentially. Today, we generate more data in two days than was generated from the dawn of civilization up until 2003.\n",
      "\n",
      "Machine learning is the key to unlocking the value in this data, and the companies that master machine learning will be the ones that dominate the market in the years to come.\n",
      "\n",
      "Learning Machine Learning\n",
      "\n",
      "Machine learning is a vast field, with many different sub-disciplines and approaches.\n",
      "\n",
      "Getting started in machine learning can be intimidating, but it doesn't have to be.\n",
      "\n",
      "With the right resources and guidance, anyone can learn machine learning and start building powerful, intelligent systems.\n",
      "\n",
      "This is where we come in.\n",
      "\n",
      "Our mission is to make machine learning accessible to everyone.\n",
      "\n",
      "We provide the resources, guidance, and support you need to learn machine learning and build your own intelligent systems.\n",
      "\n",
      "Whether you're a beginner just starting out, or an experienced developer looking to take your skills to the next level, we have something for you.\n",
      "\n",
      "Join us on this exciting journey into the world of machine learning!\n",
      "\n",
      "The Future of Machine Learning\n",
      "\n",
      "The future of machine learning is bright.\n",
      "\n",
      "With the increasing amount of data being generated, the demand for machine learning is growing, and the opportunities for innovation are endless.\n",
      "\n",
      "We are just at the beginning of this revolution, and the potential for machine learning to transform our world is enormous.\n",
      "\n",
      "We believe that machine learning will play a critical role in solving some of the biggest challenges facing humanity, from climate change\n",
      "? Generative AI is a type of artificial intelligence that can create new content, such as images, text, or music, based on patterns it has learned from existing data. It does this by using algorithms that can generate new data that is similar to the data it was trained on, but is not a direct copy.\n",
      "\n",
      "For example, a generative AI model could be trained on a large dataset of cat images. Once trained, the model could then generate new images of cats that it has never seen before, but that still look like realistic cats.\n",
      "\n",
      "Generative AI is used in a wide range of applications, including content creation, design, and even scientific research. It is a powerful tool for creating new and diverse content quickly and efficiently, and it has the potential to revolutionize many industries.\n",
      "\n",
      "However, it is important to note that generative AI is still a relatively new and rapidly evolving field, and there are many challenges that need to be addressed, such as ensuring the quality and diversity of the generated content, and preventing the misuse of generative AI for harmful purposes.\n",
      "\n",
      "Examples of generative AI include:\n",
      "\n",
      "1. Deepfakes: Deepfakes are realistic fake videos or images that are generated using generative AI. They are created by training a model on a large dataset of real images or videos, and then using the model to generate new content that looks like it was created by a real person. Deepfakes have raised concerns about privacy, misinformation, and the potential for malicious use.\n",
      "2. Text generation: Generative AI can be used to generate text, such as news articles, blog posts, or even novels. For example, a generative AI model could be trained on a large dataset of news articles, and then used to generate new articles that are similar in style and content to the ones it was trained on.\n",
      "3. Image generation: Generative AI can be used to generate images, such as new images of people, animals, or objects. For example, a generative AI model could be trained on a large dataset of cat images, and then used to generate new images of cats that it has never seen before.\n",
      "4. Music generation: Generative AI can be used to generate music, such as new songs or compositions. For example, a generative AI model could be trained on a large dataset of music, and then used to generate new music that is similar in style and structure to the music it was trained on.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example invocations\n",
    "try:\n",
    "    print(llm.invoke(\"What is Machine Learning\"))\n",
    "    print(llm.invoke(\"What is Generative AI\"))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    max_length=150,\n",
    "    temperature=0.7,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    "    timeout=60  # Increase the timeout to 60 seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} template=\"\\nQuestion: {question}\\nAnswer: Let's think step by step.\\n\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\md199\\AppData\\Local\\Temp\\ipykernel_9516\\3565542074.py:11: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"\n",
    "Question: {question}\n",
    "Answer: Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "print(prompt)\n",
    "\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Who won the cricket WorldCup 2011', 'text': 'Step 1: We know that the WorldCup is a cricket tournament.\\nStep 2: To find out who won the WorldCup in 2011, we need to look for the winner of the 2011 Cricket WorldCup.\\nStep 3: The 2011 Cricket WorldCup was held in India, Sri Lanka, and Bangladesh.\\nStep 4: The final match of the WorldCup was played between India and Sri Lanka.\\nStep 5: India won the final match by 6 wickets, becoming the World Cup champions.\\nSo, India won the cricket WorldCup 2011.'}\n"
     ]
    }
   ],
   "source": [
    "# Example invocation with an LLM chain\n",
    "try:\n",
    "    print(llm_chain.invoke(\"Who won the cricket WorldCup 2011\"))\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\md199\\AppData\\Local\\Temp\\ipykernel_9516\\1310366614.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf = HuggingFaceEmbeddings(\n",
      "d:\\Generative AI\\HuggingFace-and-Langchain-Integration\\generative14\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\md199\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\":\"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\":True}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = hf.embed_query(\"hi this is harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04366179555654526,\n",
       " -0.0192168727517128,\n",
       " 0.03780173137784004,\n",
       " -0.0554828979074955,\n",
       " 0.004219584632664919,\n",
       " 0.00959925726056099,\n",
       " 0.05980197712779045,\n",
       " 0.020596826449036598,\n",
       " 0.011896026320755482,\n",
       " 0.008097553625702858,\n",
       " 0.0031308718025684357,\n",
       " -0.07458425313234329,\n",
       " 0.02128714509308338,\n",
       " 0.028768301010131836,\n",
       " 0.01636919379234314,\n",
       " -0.0382273904979229,\n",
       " 0.04639601707458496,\n",
       " 0.0024222824722528458,\n",
       " -0.037381362169981,\n",
       " -0.0065802717581391335,\n",
       " 0.04663204401731491,\n",
       " 0.006663453299552202,\n",
       " -0.04209097847342491,\n",
       " -0.06357260793447495,\n",
       " 0.02499615028500557,\n",
       " 0.011425281874835491,\n",
       " -0.0067684343084692955,\n",
       " -0.013263978064060211,\n",
       " -0.023910321295261383,\n",
       " -0.11573262512683868,\n",
       " -0.02224602922797203,\n",
       " -0.0110789118334651,\n",
       " 0.022443478927016258,\n",
       " 0.006743002682924271,\n",
       " 0.015742002055048943,\n",
       " -0.021520065143704414,\n",
       " -0.010607651434838772,\n",
       " 0.04447277635335922,\n",
       " -0.03134218230843544,\n",
       " 0.01742258481681347,\n",
       " 0.004903232213109732,\n",
       " -0.030881574377417564,\n",
       " 0.008343331515789032,\n",
       " 0.011310838162899017,\n",
       " -0.009545558132231236,\n",
       " 0.006483911536633968,\n",
       " -0.01491217128932476,\n",
       " -0.007032346911728382,\n",
       " 0.08375494182109833,\n",
       " -0.023934483528137207,\n",
       " 0.01798851229250431,\n",
       " 0.017437350004911423,\n",
       " 0.016961442306637764,\n",
       " 0.009736397303640842,\n",
       " 0.012510755099356174,\n",
       " 0.0521661750972271,\n",
       " 0.07769057899713516,\n",
       " 0.0525028295814991,\n",
       " 0.05524851009249687,\n",
       " 0.027250148355960846,\n",
       " 0.0009136590524576604,\n",
       " 0.047924384474754333,\n",
       " -0.13805195689201355,\n",
       " 0.060186441987752914,\n",
       " 0.015228914096951485,\n",
       " -0.019039981067180634,\n",
       " -0.007625964004546404,\n",
       " -0.03697103634476662,\n",
       " 0.036970801651477814,\n",
       " 0.016125353053212166,\n",
       " -0.015695393085479736,\n",
       " 0.011873876675963402,\n",
       " 0.0357484370470047,\n",
       " 0.02785462886095047,\n",
       " 0.01470976322889328,\n",
       " -0.011886372230947018,\n",
       " 0.022315332666039467,\n",
       " 0.0014562285505235195,\n",
       " -0.015311049297451973,\n",
       " -0.0075340974144637585,\n",
       " -0.03015045076608658,\n",
       " -0.022782564163208008,\n",
       " 0.004947110079228878,\n",
       " -0.041183847934007645,\n",
       " -0.020591052249073982,\n",
       " -0.05152574181556702,\n",
       " 0.007662167306989431,\n",
       " 0.01322272140532732,\n",
       " 0.018380746245384216,\n",
       " 0.019321953877806664,\n",
       " -0.06245128810405731,\n",
       " -0.023942643776535988,\n",
       " -0.012562479823827744,\n",
       " 0.013350292108952999,\n",
       " -0.03488937020301819,\n",
       " -0.02183455042541027,\n",
       " 0.015191621147096157,\n",
       " -0.011888500303030014,\n",
       " -0.043405432254076004,\n",
       " 0.5371297001838684,\n",
       " -0.0628555491566658,\n",
       " 0.022028658539056778,\n",
       " 0.06034919619560242,\n",
       " -0.036513663828372955,\n",
       " 0.020845649763941765,\n",
       " -0.01606071926653385,\n",
       " 0.0161748044192791,\n",
       " -0.040177516639232635,\n",
       " -0.046591535210609436,\n",
       " -0.01802411675453186,\n",
       " -0.024406874552369118,\n",
       " -0.03276486322283745,\n",
       " 0.012948852963745594,\n",
       " -0.04885213077068329,\n",
       " 0.02271486259996891,\n",
       " -0.011408205144107342,\n",
       " 0.026695653796195984,\n",
       " -0.02145722508430481,\n",
       " 0.0004834612482227385,\n",
       " -0.0038157061208039522,\n",
       " -0.027638303115963936,\n",
       " 0.03278886899352074,\n",
       " -0.032632190734148026,\n",
       " 0.019761869683861732,\n",
       " 0.023273706436157227,\n",
       " -0.07965749502182007,\n",
       " 0.05436411127448082,\n",
       " 0.05964292213320732,\n",
       " 0.03717760741710663,\n",
       " 0.044174257665872574,\n",
       " -0.012672828510403633,\n",
       " -0.009952765889465809,\n",
       " -0.07422547787427902,\n",
       " -0.030055543407797813,\n",
       " -0.016596851870417595,\n",
       " -0.005999923218041658,\n",
       " -0.005789947230368853,\n",
       " 0.0027438467368483543,\n",
       " 0.02174932323396206,\n",
       " -0.041269451379776,\n",
       " -0.015061451122164726,\n",
       " -0.11061175167560577,\n",
       " -0.04324915632605553,\n",
       " -0.06395379453897476,\n",
       " 0.016365956515073776,\n",
       " 0.01308338064700365,\n",
       " -0.03655249625444412,\n",
       " 0.026498662307858467,\n",
       " -0.016822263598442078,\n",
       " 0.00891944020986557,\n",
       " -0.007903394289314747,\n",
       " 0.021263180300593376,\n",
       " -0.007365189027041197,\n",
       " -0.038218047469854355,\n",
       " 0.007081841118633747,\n",
       " 0.004390822257846594,\n",
       " 0.0301546361297369,\n",
       " 0.018570726737380028,\n",
       " 0.012463525868952274,\n",
       " 0.029790770262479782,\n",
       " 0.008402783423662186,\n",
       " -0.021170901134610176,\n",
       " -0.020868228748440742,\n",
       " 0.014705579727888107,\n",
       " 0.00470528332516551,\n",
       " -0.11569129675626755,\n",
       " -0.011803888715803623,\n",
       " 0.014223627746105194,\n",
       " 0.018010690808296204,\n",
       " 0.005592067260295153,\n",
       " 0.047691185027360916,\n",
       " 0.05560223385691643,\n",
       " -0.026473339647054672,\n",
       " 0.03488677740097046,\n",
       " 0.07888273894786835,\n",
       " 0.01366783119738102,\n",
       " -0.02881697379052639,\n",
       " 0.025512760505080223,\n",
       " -0.006240684073418379,\n",
       " -0.005673878360539675,\n",
       " 0.03504109010100365,\n",
       " -0.03200564160943031,\n",
       " -0.046049438416957855,\n",
       " -0.007944466546177864,\n",
       " 0.06592555344104767,\n",
       " 0.002907203044742346,\n",
       " -0.031146924942731857,\n",
       " -0.014136497862637043,\n",
       " -0.01638498716056347,\n",
       " 0.038736604154109955,\n",
       " 0.013465424068272114,\n",
       " 0.055591288954019547,\n",
       " -0.02279607206583023,\n",
       " -0.02654173970222473,\n",
       " -0.04548295587301254,\n",
       " 0.0015104101039469242,\n",
       " 0.024722756817936897,\n",
       " -0.016289399936795235,\n",
       " 0.0015048942295834422,\n",
       " 0.006314439699053764,\n",
       " 0.030253270640969276,\n",
       " -0.007247450761497021,\n",
       " -0.0385955274105072,\n",
       " 0.05874251574277878,\n",
       " 0.024768417701125145,\n",
       " 0.033016547560691833,\n",
       " -0.01972069963812828,\n",
       " -0.003818879835307598,\n",
       " 0.053503748029470444,\n",
       " -0.004981541074812412,\n",
       " -0.006771547719836235,\n",
       " -0.05865098163485527,\n",
       " 0.012325454503297806,\n",
       " -0.015977587550878525,\n",
       " -0.018252845853567123,\n",
       " -0.05678688734769821,\n",
       " -0.011619082652032375,\n",
       " 0.042932577431201935,\n",
       " -0.03566112369298935,\n",
       " -0.00449803750962019,\n",
       " -0.01903231255710125,\n",
       " -0.02071972005069256,\n",
       " -0.019009243696928024,\n",
       " -0.2534610629081726,\n",
       " -0.017431529238820076,\n",
       " 0.004602039698511362,\n",
       " -0.03219630569219589,\n",
       " -0.008426079526543617,\n",
       " -0.04392026737332344,\n",
       " 0.051951270550489426,\n",
       " 0.006176644470542669,\n",
       " 0.08319531381130219,\n",
       " 0.025205256417393684,\n",
       " 0.026799209415912628,\n",
       " -0.014510838314890862,\n",
       " 0.0004309221403673291,\n",
       " -0.009236634708940983,\n",
       " -0.013820072636008263,\n",
       " 0.05291789397597313,\n",
       " 0.024547254666686058,\n",
       " -0.01155672874301672,\n",
       " 0.013471688143908978,\n",
       " 0.02562079019844532,\n",
       " 0.02535538375377655,\n",
       " 0.008127291686832905,\n",
       " -0.00028980447677895427,\n",
       " -0.019214630126953125,\n",
       " 0.03601906821131706,\n",
       " -0.016906974837183952,\n",
       " 0.19389140605926514,\n",
       " 0.11227326095104218,\n",
       " 0.030804133042693138,\n",
       " 0.010343869216740131,\n",
       " 0.0064873588271439075,\n",
       " -0.020665597170591354,\n",
       " -0.0011619877768680453,\n",
       " -0.11848470568656921,\n",
       " -0.010559260845184326,\n",
       " 0.05187477916479111,\n",
       " -0.013425925746560097,\n",
       " -0.05675638094544411,\n",
       " -0.056660622358322144,\n",
       " -0.021352222189307213,\n",
       " -0.047335222363471985,\n",
       " 0.024972036480903625,\n",
       " -0.035870686173439026,\n",
       " -0.09011515229940414,\n",
       " -0.03816717118024826,\n",
       " -0.027232162654399872,\n",
       " -0.03278188779950142,\n",
       " 0.03274591267108917,\n",
       " -0.05104758217930794,\n",
       " 0.028224164620041847,\n",
       " 0.04436945915222168,\n",
       " -0.03238014131784439,\n",
       " 0.023624533787369728,\n",
       " 0.01602819561958313,\n",
       " -0.020662249997258186,\n",
       " -0.052141670137643814,\n",
       " -0.017219489440321922,\n",
       " -0.03915952518582344,\n",
       " -0.034503329545259476,\n",
       " 0.03152591735124588,\n",
       " -0.03432605788111687,\n",
       " -0.019559597596526146,\n",
       " -0.03327597677707672,\n",
       " 0.03320102393627167,\n",
       " 0.0332033634185791,\n",
       " 0.01919317990541458,\n",
       " 0.01267713587731123,\n",
       " -0.04267960041761398,\n",
       " 0.020394830033183098,\n",
       " -0.060156747698783875,\n",
       " -0.003191678784787655,\n",
       " -0.052743084728717804,\n",
       " -0.029153624549508095,\n",
       " -0.030342327430844307,\n",
       " 0.019495874643325806,\n",
       " 0.037600550800561905,\n",
       " 0.006963734049350023,\n",
       " -0.017920995131134987,\n",
       " 0.03462972491979599,\n",
       " -0.010732089169323444,\n",
       " 0.0340130589902401,\n",
       " 0.025303509086370468,\n",
       " 0.044611480087041855,\n",
       " 0.02757515013217926,\n",
       " -0.02619258686900139,\n",
       " 0.021001894026994705,\n",
       " 0.0296324510127306,\n",
       " 0.006992944981902838,\n",
       " 0.04460345581173897,\n",
       " -0.050509970635175705,\n",
       " 0.006498872302472591,\n",
       " 0.027155620977282524,\n",
       " -0.017599551007151604,\n",
       " -0.050511397421360016,\n",
       " 0.02572336606681347,\n",
       " -0.020256539806723595,\n",
       " -0.3149092197418213,\n",
       " 0.002110053086653352,\n",
       " 0.008278951980173588,\n",
       " 0.0506339855492115,\n",
       " -0.030165765434503555,\n",
       " 0.039411939680576324,\n",
       " 0.0029877491760998964,\n",
       " 0.0023377500474452972,\n",
       " -0.06381647288799286,\n",
       " 0.026654895395040512,\n",
       " -0.01906193047761917,\n",
       " 0.07660024613142014,\n",
       " 0.03535536676645279,\n",
       " -0.01926012709736824,\n",
       " -0.0008331133285537362,\n",
       " 0.039585985243320465,\n",
       " 0.02806917391717434,\n",
       " -0.026410162448883057,\n",
       " 0.01811196841299534,\n",
       " -0.03784036263823509,\n",
       " -0.029845938086509705,\n",
       " 0.013506606221199036,\n",
       " 0.21833139657974243,\n",
       " -0.02722654677927494,\n",
       " 0.05154768005013466,\n",
       " 0.010247692465782166,\n",
       " 0.0031591039150953293,\n",
       " 0.04332074895501137,\n",
       " 0.015776123851537704,\n",
       " -0.018975630402565002,\n",
       " 0.012068496085703373,\n",
       " -0.014431704767048359,\n",
       " 0.03676608204841614,\n",
       " -0.04547920450568199,\n",
       " 0.035986702889204025,\n",
       " 0.005908392835408449,\n",
       " -0.019923433661460876,\n",
       " 0.024616573005914688,\n",
       " 0.022847549989819527,\n",
       " 0.011870570480823517,\n",
       " 0.014448381960391998,\n",
       " 0.007683035917580128,\n",
       " -0.0544314906001091,\n",
       " -0.020087771117687225,\n",
       " 0.08588925749063492,\n",
       " -0.010505168698728085,\n",
       " -0.014094658195972443,\n",
       " 0.01339153852313757,\n",
       " 0.014949250966310501,\n",
       " 0.0385097973048687,\n",
       " -0.013354740105569363,\n",
       " -0.0139085091650486,\n",
       " -0.018612215295433998,\n",
       " 0.054408904165029526,\n",
       " -0.006807816680520773,\n",
       " 0.042378392070531845,\n",
       " -0.06267565488815308,\n",
       " -0.020397912710905075,\n",
       " -0.017718341201543808,\n",
       " 0.0015546518843621016,\n",
       " -0.009758343920111656,\n",
       " -0.018629247322678566,\n",
       " 0.0243272352963686,\n",
       " 0.04356963559985161,\n",
       " 0.027551749721169472]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
